{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from urllib import parse\n",
    "from bs4 import BeautifulSoup\n",
    "from locals.output_data import exportData\n",
    "from locals.date_scrape import getDate, lastStamp\n",
    "from locals.automate import By, Keys, EC, Action, wait_for, genBrowser, driverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaring the session\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "# declaring the header\n",
    "\n",
    "header = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_job function\n",
    "\n",
    "def get_job(pager, header):\n",
    "    url = \"https://jobs.issworld.com/tile-search-results/?q=&sortColumn=referencedate&sortDirection=desc&startrow={pager}&_=1686110361253\"\n",
    "\n",
    "    # payload = {}\n",
    "    # headers = {\n",
    "    # 'Accept': '*/*',\n",
    "    # 'Accept-Language': 'en-US,en;q=0.9,bn;q=0.8',\n",
    "    # 'Connection': 'keep-alive',\n",
    "    # 'Cookie': 'CookieScriptConsent={\"action\":\"reject\",\"categories\":\"[]\",\"key\":\"8f8dfd95-4925-4207-8200-6a3b1993aadf\"}; _fbp=fb.1.1685859892012.639773426; _ga=GA1.1.541051862.1685859896; JSESSIONID=w3~923EAB3B12944DDF14C1EE0943765576; _ga_HQJ22DPD35=GS1.1.1686110363.3.0.1686110363.0.0.0',\n",
    "    # 'Referer': 'https://jobs.issworld.com/search/?utm_source=CorpSite&utm_campaign=All%20Jobs%20Link',\n",
    "    # 'Sec-Fetch-Dest': 'empty',\n",
    "    # 'Sec-Fetch-Mode': 'cors',\n",
    "    # 'Sec-Fetch-Site': 'same-origin',\n",
    "    # 'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/113.0.0.0 Safari/537.36',\n",
    "    # 'X-CSRF-Token': 'b5ed7ef8-9c47-4eba-b636-6fd58b896f1f',\n",
    "    # 'X-Requested-With': 'XMLHttpRequest',\n",
    "    # 'sec-ch-ua': '\"Google Chrome\";v=\"113\", \"Chromium\";v=\"113\", \"Not-A.Brand\";v=\"24\"',\n",
    "    # 'sec-ch-ua-mobile': '?0',\n",
    "    # 'sec-ch-ua-platform': '\"macOS\"'\n",
    "    # }\n",
    "\n",
    "    # response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "    res = session.get(url, headers=header)\n",
    "\n",
    "    if res.status_code == 200:\n",
    "        return res.text\n",
    "    else:\n",
    "        print(f'Bad Response: {res.status_code}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(job_soup, job_list):\n",
    "    print('20 Jobs Scraping Started---')\n",
    "    for job_tag in job_soup:\n",
    "        job_title = job_tag.select_one('div.tiletitle span.title > a').string.replace('\\n', '').strip()\n",
    "        job_category = job_tag.select_one('div[id$=\"section-department-value\"]').string.replace('\\n', '').strip()\n",
    "        job_loc_1 = job_tag.select_one('div[id$=\"section-multilocation-value\"]').string.replace('\\n', '').strip()\n",
    "        job_loc_2 = job_tag.select_one('div[id$=\"section-customfield3-value\"]').string.replace('\\n', '').strip()\n",
    "        job_location = f'{job_loc_1}, {job_loc_2}'\n",
    "        job_posted = job_tag.select_one('div[id$=\"section-date-value\"]').string.replace('\\n', '').strip()\n",
    "\n",
    "        base_url = 'https://jobs.issworld.com'\n",
    "        job_url_tag = job_tag.select_one('div.tiletitle span.title > a')\n",
    "        job_url_text = job_url_tag['href']\n",
    "        job_url = parse.urljoin(base_url, job_url_text)\n",
    "\n",
    "        time_stamp, date_string = getDate(job_posted)\n",
    "\n",
    "        data_dict = {\n",
    "            'title': job_title,\n",
    "            'category': job_category,\n",
    "            'location': job_location,\n",
    "            'posted': date_string,\n",
    "            'job_url': job_url\n",
    "        }\n",
    "\n",
    "        print(data_dict)\n",
    "        job_list.append(data_dict)\n",
    "\n",
    "    return time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list = []\n",
    "\n",
    "for pager in range(0, 650, 20):\n",
    "    html_res = get_job(pager, header)\n",
    "\n",
    "    if not html_res:\n",
    "        print(f'return type -> {html_res}')\n",
    "    else:\n",
    "        html = html_res\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        job_tag_list = soup.select('li.job-tile')\n",
    "        # lowest_stamp = today_stamp() - 259200\n",
    "        # print(f'lowest_stamp: {lowest_stamp}')\n",
    "        time_stamp = getData(job_tag_list, job_list)\n",
    "        print(f'last job time stamp: {time_stamp}')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "print(len(job_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/json/iss_jobs.json', mode='r') as json_file:\n",
    "    json_data = json_file.read()\n",
    "    job_list = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_job_list = []\n",
    "\n",
    "header = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "for job in job_list:\n",
    "    job_url = job['job_url']\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    res = session.get(job_url, headers=header)\n",
    "    \n",
    "    if res.status_code == 200:\n",
    "        html = res.text\n",
    "\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        job_description = soup.select_one('span.jobdescription').text\n",
    "        job_description = job_description.replace('\\n', '').strip()\n",
    "\n",
    "        job['description'] = job_description\n",
    "\n",
    "        new_job_list.append(job)\n",
    "\n",
    "    else:\n",
    "        print(f'Bad Response: {res.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
